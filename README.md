# ğŸ§  Veroke AI-Powered Image Annotation Platform

**One Unified AI Platform for Image Annotation & Smart Visual Search**  
At Veroke, weâ€™re reshaping how teams and individuals interact with visual data â€” combining cutting-edge AI annotation tools with intelligent image organization and search in one seamless, web-based platform.

Whether youâ€™re labeling training data for machine learning or organizing a lifetime of digital images, our platform delivers automation, insight, and control â€” all in one place.

---

## ğŸš€ Smart AI-Powered Image Annotation â€” Built for Accuracy & Scale

Designed for AI/ML teams, researchers, and product builders, our annotation suite streamlines every step of dataset creation:

### âœ¨ Key Capabilities:
- ğŸ” **Zero-Shot Object Detection**  
  Use natural language prompts like â€œsolar panelâ€, â€œmilitary vehicleâ€, or â€œbroken windowâ€.  
  No prior training needed. Powered by **YOLOWorld** and **GroundingDINO**. (If label is in the yolo class yolo model otherwise GroundingDino)

- ğŸ–¼ **Open-Source GUI for Data Annotation**
  Our platform includes a user-friendly, open-source GUI annotation interface designed for seamless dataset creation and editing â€” directly in your browser.

- âœ… Draw / Remove Bounding Boxes
  Users can manually add or delete bounding boxes on any image to define or refine annotations.

- ğŸ· **Add New Classes On The Fly**
  Easily create new object categories via dropdown or text input, even during annotation sessions.

- ğŸ“· **Upload Your Own Images**
  Supports uploading images or loading them via API from external datasets.

- ğŸ” **Edit, Relabel, or Reassign Annotations**
  Existing bounding boxes can be reclassified, resized, or deleted in one click.

- ğŸ’¾ Annotation Autosave
  Changes are saved to disk or via API without refreshing the page.

- ğŸ“¤ Export in Standard Formats
  Annotations can be exported in COCO, Pascal VOC, or YOLO format â€” ready for training.

- ğŸ·ï¸ Multiple Annotation Methods:
  - Text Labels: Add comma-separated class labels
  - Click Labels: Add positive/negative click annotations
  - Brush Labels: Create freeform brush strokes for region selection

- âœ‚ï¸ **Auto & Manual Segmentation**  
  Detected objects are segmented instantly using **SAM** or **EfficientSAM**, with optional refinement using polygons, points, or masks.

- ğŸ“ **One-Click Dataset Export**  
  Export annotations in COCO, Pascal VOC, or YOLO formats with:
  - Cropped objects
  - Organized folder structure
  - Train/val splits
  - Class label mapping

- ğŸ” **Iterative Labeling & Human-in-the-Loop Reprocessing**  
  Upload revised annotations and regenerate outputs â€” ideal for QA cycles or dataset evolution.

- ğŸ§  **CLIP-Powered Mislabel Detection**  
  We use **CLIP + UMAP + k-NN** to visualize embeddings, identify outliers, and fix class label inconsistencies *before* model training.
  (This feature is implemented in the backend but not configured at the frontend)

- ğŸ“Š **Interactive Review Dashboards**  
  Explore data using **Plotly** visualizations â€” clusters, anomalies, and dataset quality at a glance.(also only implemented in backend)

# Data Annotation Tool

A modern web application for annotating images with various labeling methods, built with Angular and Material Design.

## Usage

1. **Upload Images**
   - Click "Select Folder" or drag and drop a folder containing images
   - Supported formats: PNG, JPEG, GIF, etc.

2. **Select an Image**
   - Click on any thumbnail in the gallery to select it for annotation
   - The selected image will be displayed in the main canvas area

3. **Add Annotations**
   - **Text Labels**:
     - Select "Text" mode
     - Enter comma-separated labels in the input field
   
   - **Box label**:
     - Select "polygon" mode
     - Click and drag to draw box

4. **Apply Preprocessing**
   - Enable desired preprocessing options
   - Adjust thresholds and parameters as needed

5. **Submit Annotations**
   - Click "Submit Annotations" to send the data
   - The payload will include all annotations and preprocessing options

## Development

- **Components**: Located in `src/app/components/`
- **Styles**: Using Tailwind CSS with Material Design
- **State Management**: Component-based with Angular's built-in features

---

## ğŸ“¸ Smart Photo Gallery â€” Visual Search & Image Management

Beyond annotation, the platform includes a visual gallery for organizing and searching image collections using the same AI backbone.

### ğŸŒŸ Features:
- ğŸ“ **Text-Based Search with CLIP**  
  Query images with phrases like *â€œbeach sunset with silhouetteâ€* or *â€œred car on snowy roadâ€* â€” and retrieve semantically matched results.

- ğŸ–¼ï¸ **Reverse Image Search**  
  Upload an image and find visually similar items, regardless of filenames or folders.

- ğŸ§¹ **Duplicate & Near-Duplicate Detection**  
  Automatically clean galleries by detecting visual redundancy.

- ğŸ§© **Image Clustering**  
  Organize massive collections with unsupervised image clustering.

---
## ğŸ“¦ Project Structure
```bash
.
â”œâ”€â”€ backend/                    # FastAPI backend
â”‚   â”œâ”€â”€ detector                # Yolo script
â”‚   â”œâ”€â”€ segmentation            # SAM scripts
â”‚   â”œâ”€â”€ utils                   # utility scripts for cropping, formatting etc.
â”‚   â”œâ”€â”€ zero_detector           # GroundingDino script
â”‚   â”œâ”€â”€ main.py                 # FastAPI entry point
â”‚   â”œâ”€â”€ requirements.txt        # Python dependencies
â”‚   â”œâ”€â”€ Dockerfile              # Backend container setup
â”‚   â””â”€â”€ models/                 # AI model weights (used by backend)
â”‚       â”œâ”€â”€ sam_vit_b_01ec64.pth
â”‚       â””â”€â”€ groundingdino_swint_ogc.pth
â”‚
â”œâ”€â”€ frontend/                   # Angular frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ angular.json
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ Dockerfile              # Frontend container setup
â”‚
â”œâ”€â”€ docker-compose.yml          # Orchestrates frontend & backend

```
---

## ğŸš€ Features

- âœ… **Click-based segmentation** using Meta's Segment Anything Model (SAM)
- âœ… **Object detection without prompts** via Grounding DINO or YOLO models
- âœ… Docker file included
- âœ… Clean separation of backend and frontend services
- âœ… REST API for programmatic annotation workflows

---

## âš™ï¸ Requirements
Download following models in models folder:
- python version used 3.10.6 cuda enabled
- https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth
- https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth
 

For Docker(optional):
- [Docker Desktop](https://www.docker.com/products/docker-desktop)
- [WSL2](https://learn.microsoft.com/en-us/windows/wsl/install) enabled (for Windows users) 
---

## ğŸ“¥ Setup Instructions

```bash
1. Clone the Repository
git clone https://github.com/Veroke-IT/AI-AutomatedImageAnnotation
cd ai-image-annotator/backend

2. Download Model Weights
Place the following .pth files in the AI-AutomatedImageAnnotation/models/ directory:

ğŸ”— SAM ViT-B Model

ğŸ”— Grounding DINO Swin-T Model

3. Create a python environment
python -m venv venv
venv\Scripts\activate  

4. Install requirements
pip install -r requirements.txt

5. Run app
uvicorn main:app --reload --port 8000

ğŸ§  Backend API: http://localhost:8000/docs

first time setup will install one time models such as yolo text encoders etc. so be patient, it will take some time.
```
```bash
ğŸ”¹ Frontend (Angular)

1. Install requirements
cd ai-image-annotator/frontend
npm install --legacy-peer-deps
npm start

```
```bash
ğŸ“¤ API Docs
Visit Swagger UI at:
ğŸ‘‰ http://localhost:8000/docs

```
```bash
ğŸ§  Models Used
Segment Anything (SAM)

Grounding DINO

EfficientSAM (if integrated)

Yolo and YoloE models

Clip models
```
---
## ğŸ” License
This project is licensed under your companyâ€™s terms or an open-source license of your choice.

## ğŸ§© Troubleshooting
âŒ Docker crashes or fails to build?
Run wsl --shutdown, restart Docker Desktop, and retry docker compose up.

## âŒ Model files not found?
Make sure both .pth files are in AI-AutomatedImageAnnotation/models/.

## ğŸ‘¥ Maintainers
Built by Veroke â€” Transforming Ideas into Digital Reality

## ğŸ¤ Letâ€™s Collaborate
Weâ€™re working with AI teams, research labs, and startups to optimize their visual data workflows.

Want a demo, integration support, or early access?
## ğŸ“¬ Reach out at https://veroke.com

